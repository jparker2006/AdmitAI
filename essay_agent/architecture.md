# ğŸ—ï¸ Essay Agent Architecture

**Version**: Post-Phase 9 (Conversational CLI)  
**Updated**: July 15 2025

---

## ğŸ¯ System Overview

â€¢ End-to-end essay assistant powered by GPT-4, orchestrated with LangGraph (ReAct pattern).  
â€¢ New **ConversationCore** bridges CLI â†” planner, providing intent parsing, natural-language â†’ tool mapping, and context upkeep.  
â€¢ **SmartPlanner v2** (planning.py) builds dynamic plans, honours deadlines/word limits, and drives evaluation-guided loops.  
â€¢ **Executor** runs LangGraph StateGraph with conditional edges, retries, and async tool calls.  
â€¢ **ToolRegistry** now stocks **35+ tools** (brainstorm â†’ polish + inline edit set).  
â€¢ **Evaluation Harness** (eval/) provides automated quality metrics and regression tests.

```mermaid
flowchart LR
    U[ğŸ‘¤ User]
    CLI[ğŸ–¥ï¸ CLI] 
    Conv[ğŸ’¬ ConversationCore]
    Planner[ğŸ§  SmartPlanner v2]
    Exec[âš™ï¸ LangGraph Executor]
    Tools[ğŸ”§ ToolRegistry]
    GPT[ğŸ¤– GPT-4 / OpenAI]
    Mem[ğŸ’¾ MemorySystem]

    U â‡„ CLI
    CLI â‡„ Conv
    Conv --> Planner
    Planner --> Exec
    Exec --> Tools
    Tools --> GPT
    Mem --> Conv
    Mem --> Planner
```

---

## ğŸ§© Component Breakdown (Post-Phase 9)

â€¢ `conversation.py` â€“ intent detection, NL â†’ tool routing, conversation memory hooks.  
â€¢ `planning.py` â€“ SmartPlanner v2: dynamic plan generation, constraint handling, evaluation-driven branching.  
â€¢ `state_manager.py` â€“ unified working + conversation memory buffers with token-aware truncation.  
â€¢ `executor.py` â€“ LangGraph StateGraph, conditional edges, retry logic, async execution.  
â€¢ `cli.py` â€“ new flags `--verbose`, `--steps`, and `essay-agent chat` mode for interactive sessions.  
â€¢ `eval/metrics.py` â€“ readability, vocabulary, similarity & rubric scorers.  
â€¢ `eval/sample_prompts.py` â€“ 5 diverse test prompts.  
â€¢ `eval/test_runs.py` â€“ pytest harness executing full workflow per prompt.

---

## ğŸ”„ Execution Flow

```mermaid
sequenceDiagram
    participant U as User
    participant C as CLI
    participant V as ConversationCore
    participant P as SmartPlanner v2
    participant E as Executor
    participant T as Tools
    participant M as Memory

    U->>C: "Write my identity essay"
    C->>V: chat message
    V->>M: load conversation + profile
    V-->>P: Intent + context
    P-->>E: EssayPlan (brainstorm â†’ outline â€¦)
    loop For each plan step
        E->>T: call tool
        T->>GPT: prompt
        GPT-->>T: result
        T-->>E: output
        E->>M: write working memory
        E-->>P: updated context
        alt Quality < threshold
            P-->>E: revision loop plan
        end
    end
    E->>M: persist essay & conversation
    E-->>C: final draft + metrics
    C-->>U: display result
```

---

## ğŸ’¾ Memory System (4 Layers)

1. **Working Memory** â€“ current step outputs, transient.  
2. **Conversation Memory** â€“ recent chat turns, manages dialog context.  
3. **Semantic Memory** â€“ user profile, writing style, values, story seeds.  
4. **Episodic Memory** â€“ historical essays, story usage tracking.

Memory APIs expose: `load_user_profile()`, `save_essay_history()`, `get_conversation_context()`, `update_working_memory()`.

---

## ğŸ–¥ï¸ CLI Commands (v2)

| Command | Purpose | Key Flags |
|---------|---------|----------|
| `essay-agent write -p "â€¦"` | Full workflow | `--verbose` (per-tool logs), `--steps` (start/stop phase) |
| `essay-agent chat` | Conversational mode | same `--verbose` |
| `essay-agent eval` | Run evaluation harness |  |

---

## ğŸ§ª Testing & Evaluation

â€¢ `pytest essay_agent/eval/test_runs.py` runs 5 sample prompts â†’ expects JSON shape, word-count Â±5 %, keyword coverage, zero tool errors.  
â€¢ Metrics captured: readability, sentence variety, vocabulary richness, prompt similarity, pass/fail.  
â€¢ Generates `EvaluationReport` dataclass per prompt.

---

## âš™ï¸ Performance & Error Handling

â€¢ Async tool calls; max concurrency = CPU cores.  
â€¢ Exponential back-off retries for network / GPT errors.  
â€¢ Evaluation-driven revision loops (quality < 8/10 â†’ revise â‰¤3 attempts).  
â€¢ CLI `--verbose` streams per-tool banners and timing.  
â€¢ Colored output via `rich` for human mode.

---

## ğŸ”® Future Roadmap

Next milestone = **Phase 10**: REST & WebSocket API exposing tools + conversation for frontend integration.  
Will add inline editing tools, FastAPI server, real-time collaboration, and production deployment scripts.